RANDOM_SEED: 133
PORT: 1111

DATASET:
  TYPE: anomaly
  NAME: MVTec
  INPUT_SIZE: [224, 224]
  IMAGE_READER:
    TYPE: opencv
    KWARGS:
      color_mode: RGB
      image_dir: /home/dulana-karunathilake/Downloads/data/mvtec_ad_resized
  CLS_IDX: ./data/MVTec-AD/cls_idx.json

  TRAIN:
    META_FILE: ./data/_onecls/mvtec_wood_zipper/train.json
    HFLIP:  [wood, zipper]
    VFLIP:  [wood, zipper]
    ROTATE: [wood, zipper]

  TEST:
    META_FILE: ./data/_onecls/mvtec_wood_zipper/test.json

  BATCH_SIZE: 2        # raise if you have VRAM
  WORKERS: 0
  PIXEL_MEAN: [0.485, 0.456, 0.406]
  PIXEL_STD:  [0.229, 0.224, 0.225]

MODEL:
  INPUT_SIZE: [224, 224]
  NUM_CLASS: 15                # keep as repo default (OK even if training on 2 classes)
  BACKBONE:
    NAME: EfficientnetB4
    TRAINABLE: False
    PRETRAINED: True
    PRETRAINED_WEIGHT_PATH: ~/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth
    EFFICIENTNET:
      LAYERS: [1, 2, 3, 4]
      STRIDES: [2, 4, 8, 16, 32]
      FEATURE_POOL_SIZE: 3
      FEATURE_JITTER_PROB: 0.5
      FEATURE_JITTER_SCALE: 20
  SEM_SEG_HEAD:
    IN_FEATURES: ["res1","res2","res3","res4"]
    CONV_DIM: 256
    NHEADS: 4
    NORM: GN
    PRE_NORM: False
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.1
    PIXEL_DECODER_NAME: TransformerEncoderPixelDecoder
    ENCODER_MASK: False
    TRANSFORMER_ENC_LAYERS: 3
    LOSS_WEIGHT: 1.0
  MASK_FORMER:
    HIDDEN_DIM: 256
    MASK_DIM: 256
    OUTPUT_CHANNELS: 3
    NUM_OBJECT_QUERIES: 196
    SIZE_DIVISIBILITY: True
    POST_GAUSSIAN: True
    NEIGHBOR_MASK:
      MASK: [False, True, True]
      NEIGHBOR_SIZE: [7, 7]
    ATTN:
      NAME: SpaticalNChannelAttn
      num_heads: 4
      dim_feedforward: 2048
      dropout: 0.1
      pre_norm: False
      cross_first: True
    ADAPTOR:
      NAME: MGG_CNN
      hidden_dim: 256
    QUERY:
      FEATURE_PROJECTOR: { NAME: 1Conv3x3, hidden_dim: 256 }
      PROCESSOR:        { NAME: LinCombWeightedQuery, base_ratio: 2, hidden_dim: 256 }
  CRITERION:
    RECON_LOSS: { NAME: ["MSE_loss", "CosSim_loss"], weight: 10 }

TRAINER:
  MAX_EPOCH: 200
  PRINT_FREQ_STEP: 10
  TB_FREQ_STEP: 1
  VAL_FREQ_EPOCH: 10
  CLIP_MAX_NORM: 0.1
  OPTIMIZER:
    TYPE: AdamW
    KWARGS: { lr: 1.0e-4, betas: [0.9, 0.999], weight_decay: 1.0e-4 }
  LR_SCHEDULER:
    TYPE: StepLR
    KWARGS: { step_size: 400, gamma: 0.1 }

SAVER:
  EXP_NAME: wood_zipper_toy
  LOG_DIR: log/
  ALWAYS_SAVE: True
  AUTO_RESUME: True
  RESUME_MODEL: ./experiments/mvtec_ad_wood_zipper/wood_zipper_toy/log/wood_zipper_toy_ckpt.pth_best.pth.tar

EVALUATOR:
  KEY_METRIC: mean_pixel_auc
  eval_dir: ./experiments/mvtec_ad_wood_zipper/wood_zipper_toy/wood_zipper_toy
  METRICS:
    AUC:
      - { NAME: std,  KWARGS: { top_percent: 1 } }
      - { NAME: max,  KWARGS: { avgpool_size: [1,1], top_percent: 1 } }
      - { NAME: pixel }
      - { NAME: ap }
      - { NAME: dice }
  VIS_COMPOUND: { SAVE_DIR: vis_compound, MIN_SCORE: null, MAX_SCORE: null }
  VIS_SINGLE:   { SAVE_DIR: vis_single,   MIN_SCORE: null, MAX_SCORE: null }

EXP_PATH: ./experiments/mvtec_ad_wood_zipper/wood_zipper_toy
LOG_PATH: ./experiments/mvtec_ad_wood_zipper/wood_zipper_toy/log/
